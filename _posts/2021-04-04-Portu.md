---
title: "Kaggle 필사 1"
excerpt: "Portu data"
date: '2021-04-04'
categories : kaggle
tags : [kaggle,portu]
use_math : true
---



```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import VarianceThreshold
from sklearn.feature_selection import SelectFromModel
from sklearn.utils import shuffle
from sklearn.ensemble import RandomForestClassifier

pd.set_option('display.max_columns', 100)
pd.set_option('display.max_rows', 100)
```


```python
%%time
train= pd.read_csv("./porto/train.csv/train.csv")
test= pd.read_csv("./porto/test.csv/test.csv")

```

    Wall time: 6.47 s



```python
# train = train.sample(frac = 0.2) EDA할 때 데이터 뽑자
# 데이터가 imbalanced하면
from sklearn.model_selection import StratifiedKFold
```


```python
#fold = StratifiedKFold(n_splits=10, random_state=1980, shuffle = True)
#for trn_idx, val_idx in fold.split(train, train['target']) :
#    break
#train = train.iloc[trn_idx]
```


```python
train.shape
```




    (595212, 59)




```python
train.tail()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>target</th>
      <th>ps_ind_01</th>
      <th>ps_ind_02_cat</th>
      <th>ps_ind_03</th>
      <th>ps_ind_04_cat</th>
      <th>ps_ind_05_cat</th>
      <th>ps_ind_06_bin</th>
      <th>ps_ind_07_bin</th>
      <th>ps_ind_08_bin</th>
      <th>ps_ind_09_bin</th>
      <th>ps_ind_10_bin</th>
      <th>ps_ind_11_bin</th>
      <th>ps_ind_12_bin</th>
      <th>ps_ind_13_bin</th>
      <th>ps_ind_14</th>
      <th>ps_ind_15</th>
      <th>ps_ind_16_bin</th>
      <th>ps_ind_17_bin</th>
      <th>ps_ind_18_bin</th>
      <th>ps_reg_01</th>
      <th>ps_reg_02</th>
      <th>ps_reg_03</th>
      <th>ps_car_01_cat</th>
      <th>ps_car_02_cat</th>
      <th>ps_car_03_cat</th>
      <th>ps_car_04_cat</th>
      <th>ps_car_05_cat</th>
      <th>ps_car_06_cat</th>
      <th>ps_car_07_cat</th>
      <th>ps_car_08_cat</th>
      <th>ps_car_09_cat</th>
      <th>ps_car_10_cat</th>
      <th>ps_car_11_cat</th>
      <th>ps_car_11</th>
      <th>ps_car_12</th>
      <th>ps_car_13</th>
      <th>ps_car_14</th>
      <th>ps_car_15</th>
      <th>ps_calc_01</th>
      <th>ps_calc_02</th>
      <th>ps_calc_03</th>
      <th>ps_calc_04</th>
      <th>ps_calc_05</th>
      <th>ps_calc_06</th>
      <th>ps_calc_07</th>
      <th>ps_calc_08</th>
      <th>ps_calc_09</th>
      <th>ps_calc_10</th>
      <th>ps_calc_11</th>
      <th>ps_calc_12</th>
      <th>ps_calc_13</th>
      <th>ps_calc_14</th>
      <th>ps_calc_15_bin</th>
      <th>ps_calc_16_bin</th>
      <th>ps_calc_17_bin</th>
      <th>ps_calc_18_bin</th>
      <th>ps_calc_19_bin</th>
      <th>ps_calc_20_bin</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>595207</th>
      <td>1488013</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>10</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>13</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.5</td>
      <td>0.3</td>
      <td>0.692820</td>
      <td>10</td>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>31</td>
      <td>3</td>
      <td>0.374166</td>
      <td>0.684631</td>
      <td>0.385487</td>
      <td>2.645751</td>
      <td>0.4</td>
      <td>0.5</td>
      <td>0.3</td>
      <td>3</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
      <td>9</td>
      <td>1</td>
      <td>12</td>
      <td>4</td>
      <td>1</td>
      <td>9</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>595208</th>
      <td>1488016</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.9</td>
      <td>0.7</td>
      <td>1.382027</td>
      <td>9</td>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
      <td>-1</td>
      <td>15</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>63</td>
      <td>2</td>
      <td>0.387298</td>
      <td>0.972145</td>
      <td>-1.000000</td>
      <td>3.605551</td>
      <td>0.2</td>
      <td>0.2</td>
      <td>0.0</td>
      <td>2</td>
      <td>4</td>
      <td>8</td>
      <td>6</td>
      <td>8</td>
      <td>2</td>
      <td>12</td>
      <td>4</td>
      <td>1</td>
      <td>3</td>
      <td>8</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>595209</th>
      <td>1488017</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.9</td>
      <td>0.2</td>
      <td>0.659071</td>
      <td>7</td>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
      <td>-1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>31</td>
      <td>3</td>
      <td>0.397492</td>
      <td>0.596373</td>
      <td>0.398748</td>
      <td>1.732051</td>
      <td>0.4</td>
      <td>0.0</td>
      <td>0.3</td>
      <td>3</td>
      <td>2</td>
      <td>7</td>
      <td>4</td>
      <td>8</td>
      <td>0</td>
      <td>10</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>595210</th>
      <td>1488021</td>
      <td>0</td>
      <td>5</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.9</td>
      <td>0.4</td>
      <td>0.698212</td>
      <td>11</td>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
      <td>-1</td>
      <td>11</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>101</td>
      <td>3</td>
      <td>0.374166</td>
      <td>0.764434</td>
      <td>0.384968</td>
      <td>3.162278</td>
      <td>0.0</td>
      <td>0.7</td>
      <td>0.0</td>
      <td>4</td>
      <td>0</td>
      <td>9</td>
      <td>4</td>
      <td>9</td>
      <td>2</td>
      <td>11</td>
      <td>4</td>
      <td>1</td>
      <td>4</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>595211</th>
      <td>1488027</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>8</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.1</td>
      <td>0.2</td>
      <td>-1.000000</td>
      <td>7</td>
      <td>0</td>
      <td>-1</td>
      <td>0</td>
      <td>-1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>34</td>
      <td>2</td>
      <td>0.400000</td>
      <td>0.932649</td>
      <td>0.378021</td>
      <td>3.741657</td>
      <td>0.4</td>
      <td>0.0</td>
      <td>0.5</td>
      <td>2</td>
      <td>3</td>
      <td>10</td>
      <td>4</td>
      <td>10</td>
      <td>2</td>
      <td>5</td>
      <td>4</td>
      <td>4</td>
      <td>3</td>
      <td>8</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
cat_cols = [col for col in train.columns if 'cat' in col]
```


```python
cat_cols
```




    ['ps_ind_02_cat',
     'ps_ind_04_cat',
     'ps_ind_05_cat',
     'ps_car_01_cat',
     'ps_car_02_cat',
     'ps_car_03_cat',
     'ps_car_04_cat',
     'ps_car_05_cat',
     'ps_car_06_cat',
     'ps_car_07_cat',
     'ps_car_08_cat',
     'ps_car_09_cat',
     'ps_car_10_cat',
     'ps_car_11_cat']




```python
train[cat_cols[0]].value_counts()
```




     1    431859
     2    123573
     3     28186
     4     11378
    -1       216
    Name: ps_ind_02_cat, dtype: int64




```python
for col in cat_cols :
    print(col, train[col].nunique())
```

    ps_ind_02_cat 5
    ps_ind_04_cat 3
    ps_ind_05_cat 8
    ps_car_01_cat 13
    ps_car_02_cat 3
    ps_car_03_cat 3
    ps_car_04_cat 10
    ps_car_05_cat 3
    ps_car_06_cat 18
    ps_car_07_cat 3
    ps_car_08_cat 2
    ps_car_09_cat 6
    ps_car_10_cat 3
    ps_car_11_cat 104



```python
train.drop_duplicates()
train.shape
```




    (595212, 59)




```python
train['ps_ind_03'].dtype == 'int64'
```




    True




```python
data = [] 

for f in train.columns:
        #Defining the role
        if f == 'target':
            role = 'target'
        elif f == 'id':
            role = 'id'
        else :
            role = 'input'
        
        #Defining the level
        if 'bin' in f or f == 'target' :
            level = 'binary'
        elif 'cat' in f or f =='id':
            level = 'nominal'
        elif train[f].dtype == 'float' :
            level = 'interval'
        elif train[f].dtype == 'int64':
            level = 'ordinal'
        
        #Initialize keep to True for all variables except for id
        keep = True
        if f == 'id':
            keep = False
        
        #Defining the data type
        dtype = train[f].dtype
        
        #Creating a Dict that contains all the metadata for the variable
        f_dict = {
            'varname' : f,
            'role' : role,
            'level' : level,
            'keep' : keep,
            'dtype' : dtype
        }
        data.append(f_dict)
        
meta = pd.DataFrame(data, columns = ['varname', 'role', 'level', 'keep', 'dtype'])
meta.set_index('varname', inplace = True)
            
```


```python
meta
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>role</th>
      <th>level</th>
      <th>keep</th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>varname</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>id</th>
      <td>id</td>
      <td>nominal</td>
      <td>False</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>target</th>
      <td>target</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_01</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_02_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_03</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_04_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_05_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_06_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_07_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_08_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_09_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_10_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_11_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_12_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_13_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_14</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_15</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_16_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_17_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_ind_18_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_reg_01</th>
      <td>input</td>
      <td>interval</td>
      <td>True</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ps_reg_02</th>
      <td>input</td>
      <td>interval</td>
      <td>True</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ps_reg_03</th>
      <td>input</td>
      <td>interval</td>
      <td>True</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ps_car_01_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_02_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_03_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_04_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_05_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_06_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_07_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_08_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_09_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_10_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_11_cat</th>
      <td>input</td>
      <td>nominal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_11</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_car_12</th>
      <td>input</td>
      <td>interval</td>
      <td>True</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ps_car_13</th>
      <td>input</td>
      <td>interval</td>
      <td>True</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ps_car_14</th>
      <td>input</td>
      <td>interval</td>
      <td>True</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ps_car_15</th>
      <td>input</td>
      <td>interval</td>
      <td>True</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ps_calc_01</th>
      <td>input</td>
      <td>interval</td>
      <td>True</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ps_calc_02</th>
      <td>input</td>
      <td>interval</td>
      <td>True</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ps_calc_03</th>
      <td>input</td>
      <td>interval</td>
      <td>True</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>ps_calc_04</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_05</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_06</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_07</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_08</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_09</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_10</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_11</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_12</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_13</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_14</th>
      <td>input</td>
      <td>ordinal</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_15_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_16_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_17_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_18_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_19_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>ps_calc_20_bin</th>
      <td>input</td>
      <td>binary</td>
      <td>True</td>
      <td>int64</td>
    </tr>
  </tbody>
</table>
</div>




```python
meta[(meta.level =='nominal')& (meta.keep)].index
```




    Index(['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat',
           'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat',
           'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat',
           'ps_car_10_cat', 'ps_car_11_cat'],
          dtype='object', name='varname')




```python
pd.DataFrame({'count' : meta.groupby(['role','level'])['role'].size()}).reset_index()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>role</th>
      <th>level</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>id</td>
      <td>nominal</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>input</td>
      <td>binary</td>
      <td>17</td>
    </tr>
    <tr>
      <th>2</th>
      <td>input</td>
      <td>interval</td>
      <td>10</td>
    </tr>
    <tr>
      <th>3</th>
      <td>input</td>
      <td>nominal</td>
      <td>14</td>
    </tr>
    <tr>
      <th>4</th>
      <td>input</td>
      <td>ordinal</td>
      <td>16</td>
    </tr>
    <tr>
      <th>5</th>
      <td>target</td>
      <td>binary</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
meta.groupby(['role','level'])['role'].size()
```




    role    level   
    id      nominal      1
    input   binary      17
            interval    10
            nominal     14
            ordinal     16
    target  binary       1
    Name: role, dtype: int64




```python
v = meta[(meta.level == 'interval') & (meta.keep)].index
train[v].describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ps_reg_01</th>
      <th>ps_reg_02</th>
      <th>ps_reg_03</th>
      <th>ps_car_12</th>
      <th>ps_car_13</th>
      <th>ps_car_14</th>
      <th>ps_car_15</th>
      <th>ps_calc_01</th>
      <th>ps_calc_02</th>
      <th>ps_calc_03</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.610991</td>
      <td>0.439184</td>
      <td>0.551102</td>
      <td>0.379945</td>
      <td>0.813265</td>
      <td>0.276256</td>
      <td>3.065899</td>
      <td>0.449756</td>
      <td>0.449589</td>
      <td>0.449849</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.287643</td>
      <td>0.404264</td>
      <td>0.793506</td>
      <td>0.058327</td>
      <td>0.224588</td>
      <td>0.357154</td>
      <td>0.731366</td>
      <td>0.287198</td>
      <td>0.286893</td>
      <td>0.287153</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>0.250619</td>
      <td>-1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.400000</td>
      <td>0.200000</td>
      <td>0.525000</td>
      <td>0.316228</td>
      <td>0.670867</td>
      <td>0.333167</td>
      <td>2.828427</td>
      <td>0.200000</td>
      <td>0.200000</td>
      <td>0.200000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.700000</td>
      <td>0.300000</td>
      <td>0.720677</td>
      <td>0.374166</td>
      <td>0.765811</td>
      <td>0.368782</td>
      <td>3.316625</td>
      <td>0.500000</td>
      <td>0.400000</td>
      <td>0.500000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.900000</td>
      <td>0.600000</td>
      <td>1.000000</td>
      <td>0.400000</td>
      <td>0.906190</td>
      <td>0.396485</td>
      <td>3.605551</td>
      <td>0.700000</td>
      <td>0.700000</td>
      <td>0.700000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.900000</td>
      <td>1.800000</td>
      <td>4.037945</td>
      <td>1.264911</td>
      <td>3.720626</td>
      <td>0.636396</td>
      <td>3.741657</td>
      <td>0.900000</td>
      <td>0.900000</td>
      <td>0.900000</td>
    </tr>
  </tbody>
</table>
</div>




```python
v = meta[(meta.level == 'binary') & (meta.keep)].index
train[v].describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>target</th>
      <th>ps_ind_06_bin</th>
      <th>ps_ind_07_bin</th>
      <th>ps_ind_08_bin</th>
      <th>ps_ind_09_bin</th>
      <th>ps_ind_10_bin</th>
      <th>ps_ind_11_bin</th>
      <th>ps_ind_12_bin</th>
      <th>ps_ind_13_bin</th>
      <th>ps_ind_16_bin</th>
      <th>ps_ind_17_bin</th>
      <th>ps_ind_18_bin</th>
      <th>ps_calc_15_bin</th>
      <th>ps_calc_16_bin</th>
      <th>ps_calc_17_bin</th>
      <th>ps_calc_18_bin</th>
      <th>ps_calc_19_bin</th>
      <th>ps_calc_20_bin</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
      <td>595212.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.036448</td>
      <td>0.393742</td>
      <td>0.257033</td>
      <td>0.163921</td>
      <td>0.185304</td>
      <td>0.000373</td>
      <td>0.001692</td>
      <td>0.009439</td>
      <td>0.000948</td>
      <td>0.660823</td>
      <td>0.121081</td>
      <td>0.153446</td>
      <td>0.122427</td>
      <td>0.627840</td>
      <td>0.554182</td>
      <td>0.287182</td>
      <td>0.349024</td>
      <td>0.153318</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.187401</td>
      <td>0.488579</td>
      <td>0.436998</td>
      <td>0.370205</td>
      <td>0.388544</td>
      <td>0.019309</td>
      <td>0.041097</td>
      <td>0.096693</td>
      <td>0.030768</td>
      <td>0.473430</td>
      <td>0.326222</td>
      <td>0.360417</td>
      <td>0.327779</td>
      <td>0.483381</td>
      <td>0.497056</td>
      <td>0.452447</td>
      <td>0.476662</td>
      <td>0.360295</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



# Handling Imbalanced classes

* 3가지 전략
    * oversampling recoreds with target == 1
    * undesrsampling records with target == 0
    * SMOTE사용 


```python
desired_apriro1=0.1
idx_0 = train[train.target == 0].index
idx_1 = train[train.target == 1].index

nb_0 = len(train.loc[idx_0])
nb_1 = len(train.loc[idx_1])
```


```python
undersampling_rate = ((1-desired_apriro1)*nb_1)/(nb_0*desired_apriro1)
```


```python
((1-desired_apriro1)*nb_1)/(nb_0*desired_apriro1)
```




    0.34043569687437886




```python
undersampled_nb_0 = int(undersampling_rate*nb_0)
print('Rate to undersample records with target=0: {}'.format(undersampling_rate))
print('Number of records with target=0 after undersampling: {}'.format(undersampled_nb_0))
```

    Rate to undersample records with target=0: 0.34043569687437886
    Number of records with target=0 after undersampling: 195246



```python
undersampled_idx = shuffle(idx_0, random_state=37, n_samples = undersampled_nb_0)
```


```python
idx_list = list(undersampled_idx) + list(idx_1)
```


```python
train = train.loc[idx_list].reset_index(drop = True)
```


```python
#import missingno as msno
```


```python
#msno.matrix(train)
```


```python
display( train.isnull().sum(axis =0) )
```


    id                0
    target            0
    ps_ind_01         0
    ps_ind_02_cat     0
    ps_ind_03         0
    ps_ind_04_cat     0
    ps_ind_05_cat     0
    ps_ind_06_bin     0
    ps_ind_07_bin     0
    ps_ind_08_bin     0
    ps_ind_09_bin     0
    ps_ind_10_bin     0
    ps_ind_11_bin     0
    ps_ind_12_bin     0
    ps_ind_13_bin     0
    ps_ind_14         0
    ps_ind_15         0
    ps_ind_16_bin     0
    ps_ind_17_bin     0
    ps_ind_18_bin     0
    ps_reg_01         0
    ps_reg_02         0
    ps_reg_03         0
    ps_car_01_cat     0
    ps_car_02_cat     0
    ps_car_03_cat     0
    ps_car_04_cat     0
    ps_car_05_cat     0
    ps_car_06_cat     0
    ps_car_07_cat     0
    ps_car_08_cat     0
    ps_car_09_cat     0
    ps_car_10_cat     0
    ps_car_11_cat     0
    ps_car_11         0
    ps_car_12         0
    ps_car_13         0
    ps_car_14         0
    ps_car_15         0
    ps_calc_01        0
    ps_calc_02        0
    ps_calc_03        0
    ps_calc_04        0
    ps_calc_05        0
    ps_calc_06        0
    ps_calc_07        0
    ps_calc_08        0
    ps_calc_09        0
    ps_calc_10        0
    ps_calc_11        0
    ps_calc_12        0
    ps_calc_13        0
    ps_calc_14        0
    ps_calc_15_bin    0
    ps_calc_16_bin    0
    ps_calc_17_bin    0
    ps_calc_18_bin    0
    ps_calc_19_bin    0
    ps_calc_20_bin    0
    dtype: int64



```python
vars_with_missing = []

for f in train.columns:
    missings = train[train[f] == -1][f].count()
    if missings > 0:
        vars_with_missing.append(f)
        missings_perc = missings/train.shape[0]
        
        print('Variable {} has {} records ({:.2%}) with missing values'.format(f,missings,missings_perc))

print('In total, there are {} variables with missing values'.format(len(vars_with_missing)))
```

    Variable ps_ind_02_cat has 103 records (0.05%) with missing values
    Variable ps_ind_04_cat has 51 records (0.02%) with missing values
    Variable ps_ind_05_cat has 2256 records (1.04%) with missing values
    Variable ps_reg_03 has 38580 records (17.78%) with missing values
    Variable ps_car_01_cat has 62 records (0.03%) with missing values
    Variable ps_car_02_cat has 2 records (0.00%) with missing values
    Variable ps_car_03_cat has 148367 records (68.39%) with missing values
    Variable ps_car_05_cat has 96026 records (44.26%) with missing values
    Variable ps_car_07_cat has 4431 records (2.04%) with missing values
    Variable ps_car_09_cat has 230 records (0.11%) with missing values
    Variable ps_car_11 has 1 records (0.00%) with missing values
    Variable ps_car_14 has 15726 records (7.25%) with missing values
    In total, there are 12 variables with missing values


-ps_car_03이 70% missing value, 전체삭제


```python
train[['ps_car_03_cat','target']].groupby('ps_car_03_cat').mean()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>target</th>
    </tr>
    <tr>
      <th>ps_car_03_cat</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>-1</th>
      <td>0.090654</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.106983</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.128862</td>
    </tr>
  </tbody>
</table>
</div>




```python
train['ps_car_03_cat'].describe()
```




    count    216940.000000
    mean         -0.492639
    std           0.795291
    min          -1.000000
    25%          -1.000000
    50%          -1.000000
    75%           0.000000
    max           1.000000
    Name: ps_car_03_cat, dtype: float64




```python
train['ps_car_03_cat'].hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x2398fb97108>




![png](output_35_1.png)


여기서는 결측값을 평균으로 대체하지만 좀더 면밀하게 분석하고 해야할 필요가있다..


```python
vars_to_drop = ['ps_car_03_cat', 'ps_car_05_cat']

train.drop(vars_to_drop, axis =1, inplace = True)
```


```python
meta.loc[(vars_to_drop), 'keep'] = False
```


```python
temp_series = train[['ps_car_01_cat','ps_car_02_cat','ps_reg_03']].groupby(['ps_car_01_cat','ps_car_02_cat']).mean()
```


```python
temp_series.reset_index(inplace= True)
```


```python
train.loc[train['ps_reg_03'] == -1].merge(temp_series, on = ['ps_car_01_cat','ps_car_02_cat'] , how = 'left')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>target</th>
      <th>ps_ind_01</th>
      <th>ps_ind_02_cat</th>
      <th>ps_ind_03</th>
      <th>ps_ind_04_cat</th>
      <th>ps_ind_05_cat</th>
      <th>ps_ind_06_bin</th>
      <th>ps_ind_07_bin</th>
      <th>ps_ind_08_bin</th>
      <th>ps_ind_09_bin</th>
      <th>ps_ind_10_bin</th>
      <th>ps_ind_11_bin</th>
      <th>ps_ind_12_bin</th>
      <th>ps_ind_13_bin</th>
      <th>ps_ind_14</th>
      <th>ps_ind_15</th>
      <th>ps_ind_16_bin</th>
      <th>ps_ind_17_bin</th>
      <th>ps_ind_18_bin</th>
      <th>ps_reg_01</th>
      <th>ps_reg_02</th>
      <th>ps_reg_03_x</th>
      <th>ps_car_01_cat</th>
      <th>ps_car_02_cat</th>
      <th>ps_car_04_cat</th>
      <th>ps_car_06_cat</th>
      <th>ps_car_07_cat</th>
      <th>ps_car_08_cat</th>
      <th>ps_car_09_cat</th>
      <th>ps_car_10_cat</th>
      <th>ps_car_11_cat</th>
      <th>ps_car_11</th>
      <th>ps_car_12</th>
      <th>ps_car_13</th>
      <th>ps_car_14</th>
      <th>ps_car_15</th>
      <th>ps_calc_01</th>
      <th>ps_calc_02</th>
      <th>ps_calc_03</th>
      <th>ps_calc_04</th>
      <th>ps_calc_05</th>
      <th>ps_calc_06</th>
      <th>ps_calc_07</th>
      <th>ps_calc_08</th>
      <th>ps_calc_09</th>
      <th>ps_calc_10</th>
      <th>ps_calc_11</th>
      <th>ps_calc_12</th>
      <th>ps_calc_13</th>
      <th>ps_calc_14</th>
      <th>ps_calc_15_bin</th>
      <th>ps_calc_16_bin</th>
      <th>ps_calc_17_bin</th>
      <th>ps_calc_18_bin</th>
      <th>ps_calc_19_bin</th>
      <th>ps_calc_20_bin</th>
      <th>ps_reg_03_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1254786</td>
      <td>0</td>
      <td>7</td>
      <td>1</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.2</td>
      <td>0.2</td>
      <td>-1.0</td>
      <td>0</td>
      <td>1</td>
      <td>9</td>
      <td>13</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>104</td>
      <td>2</td>
      <td>0.565685</td>
      <td>2.108264</td>
      <td>0.530094</td>
      <td>3.741657</td>
      <td>0.7</td>
      <td>0.6</td>
      <td>0.4</td>
      <td>2</td>
      <td>2</td>
      <td>9</td>
      <td>3</td>
      <td>11</td>
      <td>1</td>
      <td>12</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>10</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.505736</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1425558</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>8</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>-1.0</td>
      <td>8</td>
      <td>1</td>
      <td>0</td>
      <td>14</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>104</td>
      <td>1</td>
      <td>0.316070</td>
      <td>0.508502</td>
      <td>0.355668</td>
      <td>1.732051</td>
      <td>0.0</td>
      <td>0.4</td>
      <td>0.1</td>
      <td>1</td>
      <td>2</td>
      <td>9</td>
      <td>2</td>
      <td>12</td>
      <td>3</td>
      <td>6</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>10</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.515147</td>
    </tr>
    <tr>
      <th>2</th>
      <td>860206</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.4</td>
      <td>0.1</td>
      <td>-1.0</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>64</td>
      <td>1</td>
      <td>0.316228</td>
      <td>0.656405</td>
      <td>0.361939</td>
      <td>3.316625</td>
      <td>0.4</td>
      <td>0.8</td>
      <td>0.3</td>
      <td>3</td>
      <td>1</td>
      <td>6</td>
      <td>3</td>
      <td>7</td>
      <td>2</td>
      <td>7</td>
      <td>6</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.333647</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1265316</td>
      <td>0</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>-1.0</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>65</td>
      <td>1</td>
      <td>0.316228</td>
      <td>0.545795</td>
      <td>0.350714</td>
      <td>2.449490</td>
      <td>0.6</td>
      <td>0.6</td>
      <td>0.5</td>
      <td>1</td>
      <td>1</td>
      <td>7</td>
      <td>1</td>
      <td>12</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>2</td>
      <td>4</td>
      <td>10</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.244300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>267652</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.3</td>
      <td>0.3</td>
      <td>-1.0</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>10</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>55</td>
      <td>2</td>
      <td>0.424264</td>
      <td>1.116425</td>
      <td>0.416533</td>
      <td>3.605551</td>
      <td>0.2</td>
      <td>0.1</td>
      <td>0.9</td>
      <td>2</td>
      <td>0</td>
      <td>8</td>
      <td>4</td>
      <td>12</td>
      <td>3</td>
      <td>9</td>
      <td>7</td>
      <td>0</td>
      <td>2</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0.477232</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>38575</th>
      <td>1486851</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>10</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>-1.0</td>
      <td>11</td>
      <td>0</td>
      <td>9</td>
      <td>17</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>104</td>
      <td>2</td>
      <td>0.447214</td>
      <td>1.209873</td>
      <td>0.430116</td>
      <td>3.316625</td>
      <td>0.2</td>
      <td>0.4</td>
      <td>0.9</td>
      <td>2</td>
      <td>3</td>
      <td>7</td>
      <td>4</td>
      <td>8</td>
      <td>4</td>
      <td>8</td>
      <td>7</td>
      <td>0</td>
      <td>6</td>
      <td>10</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0.985341</td>
    </tr>
    <tr>
      <th>38576</th>
      <td>1487090</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>6</td>
      <td>0</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>-1.0</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>37</td>
      <td>2</td>
      <td>0.316228</td>
      <td>0.740728</td>
      <td>0.311448</td>
      <td>3.316625</td>
      <td>0.4</td>
      <td>0.7</td>
      <td>0.0</td>
      <td>1</td>
      <td>2</td>
      <td>9</td>
      <td>6</td>
      <td>9</td>
      <td>1</td>
      <td>10</td>
      <td>6</td>
      <td>1</td>
      <td>3</td>
      <td>15</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0.333647</td>
    </tr>
    <tr>
      <th>38577</th>
      <td>1487406</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>8</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.4</td>
      <td>0.0</td>
      <td>-1.0</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>64</td>
      <td>3</td>
      <td>0.316228</td>
      <td>0.613586</td>
      <td>0.301662</td>
      <td>2.828427</td>
      <td>0.9</td>
      <td>0.5</td>
      <td>0.5</td>
      <td>3</td>
      <td>1</td>
      <td>10</td>
      <td>2</td>
      <td>9</td>
      <td>1</td>
      <td>3</td>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.333647</td>
    </tr>
    <tr>
      <th>38578</th>
      <td>1487419</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>9</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.3</td>
      <td>0.3</td>
      <td>-1.0</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>34</td>
      <td>2</td>
      <td>0.400000</td>
      <td>0.795156</td>
      <td>0.378021</td>
      <td>3.162278</td>
      <td>0.7</td>
      <td>0.1</td>
      <td>0.9</td>
      <td>3</td>
      <td>4</td>
      <td>9</td>
      <td>3</td>
      <td>9</td>
      <td>2</td>
      <td>8</td>
      <td>11</td>
      <td>1</td>
      <td>5</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.244300</td>
    </tr>
    <tr>
      <th>38579</th>
      <td>1487566</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0.3</td>
      <td>0.4</td>
      <td>-1.0</td>
      <td>11</td>
      <td>0</td>
      <td>0</td>
      <td>15</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>5</td>
      <td>2</td>
      <td>0.424264</td>
      <td>0.756979</td>
      <td>0.400000</td>
      <td>2.000000</td>
      <td>0.3</td>
      <td>0.4</td>
      <td>0.6</td>
      <td>1</td>
      <td>1</td>
      <td>8</td>
      <td>2</td>
      <td>9</td>
      <td>5</td>
      <td>9</td>
      <td>9</td>
      <td>2</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.985341</td>
    </tr>
  </tbody>
</table>
<p>38580 rows × 58 columns</p>
</div>




```python
mean_imp = SimpleImputer(missing_values= -1, strategy='mean')
mode_imp = SimpleImputer(missing_values= -1, strategy ='most_frequent')
```


```python
train['ps_reg_03'] = mean_imp.fit_transform(train[['ps_reg_03']]).ravel()
train['ps_car_12'] = mean_imp.fit_transform(train[['ps_car_12']]).ravel()
train['ps_car_14'] = mean_imp.fit_transform(train[['ps_car_14']]).ravel()
train['ps_car_11'] = mode_imp.fit_transform(train[['ps_car_11']]).ravel()
```


```python
v = meta[(meta.level == 'nominal' ) & (meta.keep)].index
sum = 0

for f in v :
    dist_values = train[f].value_counts().shape[0]
    sum+= dist_values
    print('Variable {} has {} distinct values'.format(f, dist_values))
```

    Variable ps_ind_02_cat has 5 distinct values
    Variable ps_ind_04_cat has 3 distinct values
    Variable ps_ind_05_cat has 8 distinct values
    Variable ps_car_01_cat has 13 distinct values
    Variable ps_car_02_cat has 3 distinct values
    Variable ps_car_04_cat has 10 distinct values
    Variable ps_car_06_cat has 18 distinct values
    Variable ps_car_07_cat has 3 distinct values
    Variable ps_car_08_cat has 2 distinct values
    Variable ps_car_09_cat has 6 distinct values
    Variable ps_car_10_cat has 3 distinct values
    Variable ps_car_11_cat has 104 distinct values



```python
train[f].value_counts().shape
```




    (104,)




```python
sum
```




    178




```python

def add_noise(series, noise_level):
    return series * (1 + noise_level * np.random.randn(len(series)))

def target_encode(trn_series=None, 
                  tst_series=None, 
                  target=None, 
                  min_samples_leaf=1, 
                  smoothing=1,
                  noise_level=0):
    """
    Smoothing is computed like in the following paper by Daniele Micci-Barreca
    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf
    trn_series : training categorical feature as a pd.Series
    tst_series : test categorical feature as a pd.Series
    target : target data as a pd.Series
    min_samples_leaf (int) : minimum samples to take category average into account
    smoothing (int) : smoothing effect to balance categorical average vs prior  
    """ 
    assert len(trn_series) == len(target) #값이 같으면 True 
    assert trn_series.name == tst_series.name
    temp = pd.concat([trn_series, target], axis=1) #옆으로 붙여주고,
    # Compute target mean 
    averages = temp.groupby(by=trn_series.name)[target.name].agg(["mean", "count"]) #group by
    # Compute smoothing
    smoothing = 1 / (1 + np.exp(-(averages["count"] - min_samples_leaf) / smoothing))
    # Apply average function to all target data
    prior = target.mean()
    # The bigger the count the less full_avg is taken into account
    averages[target.name] = prior * (1 - smoothing) + averages["mean"] * smoothing
    averages.drop(["mean", "count"], axis=1, inplace=True)
    # Apply averages to trn and tst series
    ft_trn_series = pd.merge(
        trn_series.to_frame(trn_series.name),
        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),#rename
        on=trn_series.name,                                                                 # merge 
        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior) # how = left를 넣어야 NULL값이 안생김
    
    # pd.merge does not keep the index so restore it
    ft_trn_series.index = trn_series.index 
    ft_tst_series = pd.merge(
        tst_series.to_frame(tst_series.name),
        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),
        on=tst_series.name,
        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)
    # pd.merge does not keep the index so restore it
    ft_tst_series.index = tst_series.index
    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)
```


```python
train_encoded, test_encoded = target_encode(train["ps_car_11_cat"], 
                             test["ps_car_11_cat"], 
                             target=train.target, 
                             min_samples_leaf=100,
                             smoothing=10,
                             noise_level=0.01)
    
train['ps_car_11_cat_te'] = train_encoded
train.drop('ps_car_11_cat', axis=1, inplace=True)
meta.loc['ps_car_11_cat','keep'] = False  # Updating the meta
test['ps_car_11_cat_te'] = test_encoded
test.drop('ps_car_11_cat', axis=1, inplace=True)
```

#### 뜯어보기


```python
#v = meta[(meta.level == 'nominal') & (meta.keep)].index

```


```python
#cat_perc = train[[f, 'target']].groupby([f],as_index=False).mean()
```


    ---------------------------------------------------------------------------
    
    KeyError                                  Traceback (most recent call last)
    
    <ipython-input-50-b8a6304ecf30> in <module>
    ----> 1 cat_perc = train[[f, 'target']].groupby([f],as_index=False).mean()


    C:\Anaconda3\lib\site-packages\pandas\core\frame.py in __getitem__(self, key)
       2804             if is_iterator(key):
       2805                 key = list(key)
    -> 2806             indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]
       2807 
       2808         # take() does not accept boolean indexers


    C:\Anaconda3\lib\site-packages\pandas\core\indexing.py in _get_listlike_indexer(self, key, axis, raise_missing)
       1550 
       1551         self._validate_read_indexer(
    -> 1552             keyarr, indexer, o._get_axis_number(axis), raise_missing=raise_missing
       1553         )
       1554         return keyarr, indexer


    C:\Anaconda3\lib\site-packages\pandas\core\indexing.py in _validate_read_indexer(self, key, indexer, axis, raise_missing)
       1643             if not (self.name == "loc" and not raise_missing):
       1644                 not_found = list(set(key) - set(ax))
    -> 1645                 raise KeyError(f"{not_found} not in index")
       1646 
       1647             # we skip the warning on Categorical/Interval


    KeyError: "['ps_car_11_cat'] not in index"



```python
#cat_perc
```


    ---------------------------------------------------------------------------
    
    NameError                                 Traceback (most recent call last)
    
    <ipython-input-51-2ac23d9b437a> in <module>
    ----> 1 cat_perc


    NameError: name 'cat_perc' is not defined



```python
#cat_perc.sort_values(by='target', ascending=False, inplace = True)
```


    ---------------------------------------------------------------------------
    
    NameError                                 Traceback (most recent call last)
    
    <ipython-input-52-72bd5321c2f0> in <module>
    ----> 1 cat_perc.sort_values(by='target', ascending=False, inplace = True)


    NameError: name 'cat_perc' is not defined



```python
#sns.barplot(x=f, y = 'target', data=cat_perc,order = cat_perc[f])

```


    ---------------------------------------------------------------------------
    
    NameError                                 Traceback (most recent call last)
    
    <ipython-input-53-579ec202cb69> in <module>
    ----> 1 sns.barplot(x=f, y = 'target', data=cat_perc,order = cat_perc[f])


    NameError: name 'cat_perc' is not defined


#### 다시 코드


```python
v = meta[(meta.level == 'nominal') & (meta.keep)].index

for f in v:
    plt.figure()
    fig, ax = plt.subplots(figsize=(20,10))
    # Calculate the percentage of target=1 per category value
    cat_perc = train[[f, 'target']].groupby([f],as_index=False).mean()
    cat_perc.sort_values(by='target', ascending=False, inplace=True)
    # Bar plot
    # Order the bars descending on target mean
    sns.barplot(ax=ax, x=f, y='target', data=cat_perc, order=cat_perc[f])
    plt.ylabel('% target', fontsize=18)
    plt.xlabel(f, fontsize=18)
    plt.tick_params(axis='both', which='major', labelsize=18)
    plt.show();
```


    <Figure size 432x288 with 0 Axes>



![png](output_56_1.png)



    <Figure size 432x288 with 0 Axes>



![png](output_56_3.png)



    <Figure size 432x288 with 0 Axes>



![png](output_56_5.png)



    <Figure size 432x288 with 0 Axes>



![png](output_56_7.png)



    <Figure size 432x288 with 0 Axes>



![png](output_56_9.png)



    <Figure size 432x288 with 0 Axes>



![png](output_56_11.png)



    <Figure size 432x288 with 0 Axes>



![png](output_56_13.png)



    <Figure size 432x288 with 0 Axes>



![png](output_56_15.png)



    <Figure size 432x288 with 0 Axes>



![png](output_56_17.png)



    <Figure size 432x288 with 0 Axes>



![png](output_56_19.png)



    <Figure size 432x288 with 0 Axes>



![png](output_56_21.png)



```python
cat_perc
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ps_car_10_cat</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0.100029</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0.100000</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0.096420</td>
    </tr>
  </tbody>
</table>
</div>




```python
f = 'ps_car_02_cat'
```


```python
cat_perc = train[[f, 'target']].groupby([f], as_index=False).agg(['mean','count'])
```


```python
cat_perc
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead tr th {
        text-align: left;
    }
    
    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">target</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>count</th>
    </tr>
    <tr>
      <th>ps_car_02_cat</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>-1</th>
      <td>0.000000</td>
      <td>2</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.131868</td>
      <td>38000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.093233</td>
      <td>178938</td>
    </tr>
  </tbody>
</table>
</div>



* 관측값이 2개밖에 없는데 둘다 -1이여서 확률이 0으로 나타남. 
* 여기서는 결측치가 의미가 있다고 판단하여 삭제하지 않음.



```python
v = meta[(meta.level == 'interval') & (meta.keep)].index
```


```python
correlations = train[v].corr()
```


```python
correlations
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ps_reg_01</th>
      <th>ps_reg_02</th>
      <th>ps_reg_03</th>
      <th>ps_car_12</th>
      <th>ps_car_13</th>
      <th>ps_car_14</th>
      <th>ps_car_15</th>
      <th>ps_calc_01</th>
      <th>ps_calc_02</th>
      <th>ps_calc_03</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ps_reg_01</th>
      <td>1.000000</td>
      <td>0.470953</td>
      <td>0.137117</td>
      <td>0.019095</td>
      <td>0.025243</td>
      <td>-0.002536</td>
      <td>0.001755</td>
      <td>-0.003236</td>
      <td>0.001459</td>
      <td>-0.001371</td>
    </tr>
    <tr>
      <th>ps_reg_02</th>
      <td>0.470953</td>
      <td>1.000000</td>
      <td>0.702512</td>
      <td>0.173736</td>
      <td>0.193896</td>
      <td>0.053149</td>
      <td>0.052344</td>
      <td>-0.001769</td>
      <td>-0.000726</td>
      <td>-0.000992</td>
    </tr>
    <tr>
      <th>ps_reg_03</th>
      <td>0.137117</td>
      <td>0.702512</td>
      <td>1.000000</td>
      <td>0.208978</td>
      <td>0.241244</td>
      <td>0.079541</td>
      <td>0.079848</td>
      <td>-0.000223</td>
      <td>0.000043</td>
      <td>-0.000357</td>
    </tr>
    <tr>
      <th>ps_car_12</th>
      <td>0.019095</td>
      <td>0.173736</td>
      <td>0.208978</td>
      <td>1.000000</td>
      <td>0.674298</td>
      <td>0.577537</td>
      <td>0.049468</td>
      <td>-0.000452</td>
      <td>-0.001070</td>
      <td>-0.000707</td>
    </tr>
    <tr>
      <th>ps_car_13</th>
      <td>0.025243</td>
      <td>0.193896</td>
      <td>0.241244</td>
      <td>0.674298</td>
      <td>1.000000</td>
      <td>0.434613</td>
      <td>0.526024</td>
      <td>0.000266</td>
      <td>0.000020</td>
      <td>0.000568</td>
    </tr>
    <tr>
      <th>ps_car_14</th>
      <td>-0.002536</td>
      <td>0.053149</td>
      <td>0.079541</td>
      <td>0.577537</td>
      <td>0.434613</td>
      <td>1.000000</td>
      <td>0.008472</td>
      <td>-0.004548</td>
      <td>-0.005015</td>
      <td>0.000776</td>
    </tr>
    <tr>
      <th>ps_car_15</th>
      <td>0.001755</td>
      <td>0.052344</td>
      <td>0.079848</td>
      <td>0.049468</td>
      <td>0.526024</td>
      <td>0.008472</td>
      <td>1.000000</td>
      <td>-0.000392</td>
      <td>0.003630</td>
      <td>0.000586</td>
    </tr>
    <tr>
      <th>ps_calc_01</th>
      <td>-0.003236</td>
      <td>-0.001769</td>
      <td>-0.000223</td>
      <td>-0.000452</td>
      <td>0.000266</td>
      <td>-0.004548</td>
      <td>-0.000392</td>
      <td>1.000000</td>
      <td>0.002832</td>
      <td>-0.000212</td>
    </tr>
    <tr>
      <th>ps_calc_02</th>
      <td>0.001459</td>
      <td>-0.000726</td>
      <td>0.000043</td>
      <td>-0.001070</td>
      <td>0.000020</td>
      <td>-0.005015</td>
      <td>0.003630</td>
      <td>0.002832</td>
      <td>1.000000</td>
      <td>0.003130</td>
    </tr>
    <tr>
      <th>ps_calc_03</th>
      <td>-0.001371</td>
      <td>-0.000992</td>
      <td>-0.000357</td>
      <td>-0.000707</td>
      <td>0.000568</td>
      <td>0.000776</td>
      <td>0.000586</td>
      <td>-0.000212</td>
      <td>0.003130</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
cmap = sns.diverging_palette(220, 10, as_cmap=True)
```


```python

    fig, ax = plt.subplots(figsize=(10,10))
    sns.heatmap(correlations, cmap=cmap, vmax=1.0, center=0, fmt='.2f',
                square=True, linewidths=.5, annot=True, cbar_kws={"shrink": .75})
    plt.show();
```


![png](output_66_0.png)



```python
def corr_heatmap(v):
    correlations = train[v].corr()

    # Create color map ranging between two colors
    cmap = sns.diverging_palette(220, 10, as_cmap=True)

    fig, ax = plt.subplots(figsize=(10,10))
    sns.heatmap(correlations, cmap=cmap, vmax=1.0, center=0, fmt='.2f',
                square=True, linewidths=.5, annot=True, cbar_kws={"shrink": .75})
    plt.show();
    
v = meta[(meta.level == 'interval') & (meta.keep)].index
corr_heatmap(v)
```


![png](output_67_0.png)



```python
s = train.sample(frac=0.1)
```


```python
sns.lmplot(x='ps_reg_02', y='ps_reg_03', data=s, hue= 'target', palette='Set1',scatter_kws = {'alpha' : 0.3})
plt.show()
```


![png](output_69_0.png)



```python
sns.lmplot(x='ps_car_12', y='ps_car_13', data=s, hue='target', palette='Set1', scatter_kws={'alpha':0.3})
plt.show()
```


![png](output_70_0.png)



```python
sns.lmplot(x='ps_car_12', y='ps_car_14', data=s, hue='target', palette='Set1', scatter_kws={'alpha':0.3})
plt.show()
```


![png](output_71_0.png)



```python
sns.lmplot(x='ps_car_15', y='ps_car_13', data=s, hue='target', palette='Set1', scatter_kws={'alpha':0.3})
plt.show()
```


![png](output_72_0.png)



```python
v = meta[(meta.level == 'ordinal') & (meta.keep)].index
corr_heatmap(v)
```


![png](output_73_0.png)



```python
#PCA를 이용해서 결정

```


```python
v = meta[(meta.level == 'nominal') & (meta.keep)].index
print('Before dummification we have {} variables in train'.format(train.shape[1]))
train = pd.get_dummies(train, columns=v, drop_first=True)
print('After dummification we have {} variables in train'.format(train.shape[1]))
```

    Before dummification we have 57 variables in train
    After dummification we have 109 variables in train



```python

v = meta[(meta.level == 'interval') & (meta.keep)].index

```


```python
poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias = False) #2승까지 

```


```python
poly.fit_transform(train[v])
```




    array([[0.6       , 0.6       , 0.83815273, ..., 0.09      , 0.        ,
            0.        ],
           [0.9       , 0.6       , 0.72844011, ..., 0.        , 0.        ,
            0.36      ],
           [0.9       , 0.6       , 0.86926693, ..., 0.81      , 0.09      ,
            0.01      ],
           ...,
           [0.9       , 0.3       , 0.71195154, ..., 0.16      , 0.24      ,
            0.36      ],
           [0.6       , 0.1       , 0.57716982, ..., 0.04      , 0.12      ,
            0.36      ],
           [0.6       , 0.4       , 1.09515981, ..., 0.36      , 0.18      ,
            0.09      ]])




```python
poly.get_feature_names(v)
```




    ['ps_reg_01',
     'ps_reg_02',
     'ps_reg_03',
     'ps_car_12',
     'ps_car_13',
     'ps_car_14',
     'ps_car_15',
     'ps_calc_01',
     'ps_calc_02',
     'ps_calc_03',
     'ps_reg_01^2',
     'ps_reg_01 ps_reg_02',
     'ps_reg_01 ps_reg_03',
     'ps_reg_01 ps_car_12',
     'ps_reg_01 ps_car_13',
     'ps_reg_01 ps_car_14',
     'ps_reg_01 ps_car_15',
     'ps_reg_01 ps_calc_01',
     'ps_reg_01 ps_calc_02',
     'ps_reg_01 ps_calc_03',
     'ps_reg_02^2',
     'ps_reg_02 ps_reg_03',
     'ps_reg_02 ps_car_12',
     'ps_reg_02 ps_car_13',
     'ps_reg_02 ps_car_14',
     'ps_reg_02 ps_car_15',
     'ps_reg_02 ps_calc_01',
     'ps_reg_02 ps_calc_02',
     'ps_reg_02 ps_calc_03',
     'ps_reg_03^2',
     'ps_reg_03 ps_car_12',
     'ps_reg_03 ps_car_13',
     'ps_reg_03 ps_car_14',
     'ps_reg_03 ps_car_15',
     'ps_reg_03 ps_calc_01',
     'ps_reg_03 ps_calc_02',
     'ps_reg_03 ps_calc_03',
     'ps_car_12^2',
     'ps_car_12 ps_car_13',
     'ps_car_12 ps_car_14',
     'ps_car_12 ps_car_15',
     'ps_car_12 ps_calc_01',
     'ps_car_12 ps_calc_02',
     'ps_car_12 ps_calc_03',
     'ps_car_13^2',
     'ps_car_13 ps_car_14',
     'ps_car_13 ps_car_15',
     'ps_car_13 ps_calc_01',
     'ps_car_13 ps_calc_02',
     'ps_car_13 ps_calc_03',
     'ps_car_14^2',
     'ps_car_14 ps_car_15',
     'ps_car_14 ps_calc_01',
     'ps_car_14 ps_calc_02',
     'ps_car_14 ps_calc_03',
     'ps_car_15^2',
     'ps_car_15 ps_calc_01',
     'ps_car_15 ps_calc_02',
     'ps_car_15 ps_calc_03',
     'ps_calc_01^2',
     'ps_calc_01 ps_calc_02',
     'ps_calc_01 ps_calc_03',
     'ps_calc_02^2',
     'ps_calc_02 ps_calc_03',
     'ps_calc_03^2']




```python
pd.DataFrame(data=poly.fit_transform(train[v]), columns=poly.get_feature_names(v))
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ps_reg_01</th>
      <th>ps_reg_02</th>
      <th>ps_reg_03</th>
      <th>ps_car_12</th>
      <th>ps_car_13</th>
      <th>ps_car_14</th>
      <th>ps_car_15</th>
      <th>ps_calc_01</th>
      <th>ps_calc_02</th>
      <th>ps_calc_03</th>
      <th>ps_reg_01^2</th>
      <th>ps_reg_01 ps_reg_02</th>
      <th>ps_reg_01 ps_reg_03</th>
      <th>ps_reg_01 ps_car_12</th>
      <th>ps_reg_01 ps_car_13</th>
      <th>ps_reg_01 ps_car_14</th>
      <th>ps_reg_01 ps_car_15</th>
      <th>ps_reg_01 ps_calc_01</th>
      <th>ps_reg_01 ps_calc_02</th>
      <th>ps_reg_01 ps_calc_03</th>
      <th>ps_reg_02^2</th>
      <th>ps_reg_02 ps_reg_03</th>
      <th>ps_reg_02 ps_car_12</th>
      <th>ps_reg_02 ps_car_13</th>
      <th>ps_reg_02 ps_car_14</th>
      <th>ps_reg_02 ps_car_15</th>
      <th>ps_reg_02 ps_calc_01</th>
      <th>ps_reg_02 ps_calc_02</th>
      <th>ps_reg_02 ps_calc_03</th>
      <th>ps_reg_03^2</th>
      <th>ps_reg_03 ps_car_12</th>
      <th>ps_reg_03 ps_car_13</th>
      <th>ps_reg_03 ps_car_14</th>
      <th>ps_reg_03 ps_car_15</th>
      <th>ps_reg_03 ps_calc_01</th>
      <th>ps_reg_03 ps_calc_02</th>
      <th>ps_reg_03 ps_calc_03</th>
      <th>ps_car_12^2</th>
      <th>ps_car_12 ps_car_13</th>
      <th>ps_car_12 ps_car_14</th>
      <th>ps_car_12 ps_car_15</th>
      <th>ps_car_12 ps_calc_01</th>
      <th>ps_car_12 ps_calc_02</th>
      <th>ps_car_12 ps_calc_03</th>
      <th>ps_car_13^2</th>
      <th>ps_car_13 ps_car_14</th>
      <th>ps_car_13 ps_car_15</th>
      <th>ps_car_13 ps_calc_01</th>
      <th>ps_car_13 ps_calc_02</th>
      <th>ps_car_13 ps_calc_03</th>
      <th>ps_car_14^2</th>
      <th>ps_car_14 ps_car_15</th>
      <th>ps_car_14 ps_calc_01</th>
      <th>ps_car_14 ps_calc_02</th>
      <th>ps_car_14 ps_calc_03</th>
      <th>ps_car_15^2</th>
      <th>ps_car_15 ps_calc_01</th>
      <th>ps_car_15 ps_calc_02</th>
      <th>ps_car_15 ps_calc_03</th>
      <th>ps_calc_01^2</th>
      <th>ps_calc_01 ps_calc_02</th>
      <th>ps_calc_01 ps_calc_03</th>
      <th>ps_calc_02^2</th>
      <th>ps_calc_02 ps_calc_03</th>
      <th>ps_calc_03^2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.6</td>
      <td>0.6</td>
      <td>0.838153</td>
      <td>0.368782</td>
      <td>0.540603</td>
      <td>0.345688</td>
      <td>2.000000</td>
      <td>0.9</td>
      <td>0.3</td>
      <td>0.0</td>
      <td>0.36</td>
      <td>0.36</td>
      <td>0.502892</td>
      <td>0.221269</td>
      <td>0.324362</td>
      <td>0.207413</td>
      <td>1.200000</td>
      <td>0.54</td>
      <td>0.18</td>
      <td>0.00</td>
      <td>0.36</td>
      <td>0.502892</td>
      <td>0.221269</td>
      <td>0.324362</td>
      <td>0.207413</td>
      <td>1.200000</td>
      <td>0.54</td>
      <td>0.18</td>
      <td>0.00</td>
      <td>0.702500</td>
      <td>0.309095</td>
      <td>0.453108</td>
      <td>0.289739</td>
      <td>1.676305</td>
      <td>0.754337</td>
      <td>0.251446</td>
      <td>0.000000</td>
      <td>0.136</td>
      <td>0.199365</td>
      <td>0.127483</td>
      <td>0.737564</td>
      <td>0.331904</td>
      <td>0.110635</td>
      <td>0.000000</td>
      <td>0.292252</td>
      <td>0.186880</td>
      <td>1.081207</td>
      <td>0.486543</td>
      <td>0.162181</td>
      <td>0.000000</td>
      <td>0.1195</td>
      <td>0.691375</td>
      <td>0.311119</td>
      <td>0.103706</td>
      <td>0.000000</td>
      <td>4.0</td>
      <td>1.800000</td>
      <td>0.600000</td>
      <td>0.000000</td>
      <td>0.81</td>
      <td>0.27</td>
      <td>0.00</td>
      <td>0.09</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.9</td>
      <td>0.6</td>
      <td>0.728440</td>
      <td>0.424264</td>
      <td>0.382953</td>
      <td>0.378814</td>
      <td>0.000000</td>
      <td>0.2</td>
      <td>0.0</td>
      <td>0.6</td>
      <td>0.81</td>
      <td>0.54</td>
      <td>0.655596</td>
      <td>0.381838</td>
      <td>0.344658</td>
      <td>0.340933</td>
      <td>0.000000</td>
      <td>0.18</td>
      <td>0.00</td>
      <td>0.54</td>
      <td>0.36</td>
      <td>0.437064</td>
      <td>0.254558</td>
      <td>0.229772</td>
      <td>0.227288</td>
      <td>0.000000</td>
      <td>0.12</td>
      <td>0.00</td>
      <td>0.36</td>
      <td>0.530625</td>
      <td>0.309051</td>
      <td>0.278958</td>
      <td>0.275943</td>
      <td>0.000000</td>
      <td>0.145688</td>
      <td>0.000000</td>
      <td>0.437064</td>
      <td>0.180</td>
      <td>0.162473</td>
      <td>0.160717</td>
      <td>0.000000</td>
      <td>0.084853</td>
      <td>0.000000</td>
      <td>0.254558</td>
      <td>0.146653</td>
      <td>0.145068</td>
      <td>0.000000</td>
      <td>0.076591</td>
      <td>0.000000</td>
      <td>0.229772</td>
      <td>0.1435</td>
      <td>0.000000</td>
      <td>0.075763</td>
      <td>0.000000</td>
      <td>0.227288</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.04</td>
      <td>0.00</td>
      <td>0.12</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.36</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.9</td>
      <td>0.6</td>
      <td>0.869267</td>
      <td>0.400000</td>
      <td>0.814271</td>
      <td>0.402368</td>
      <td>3.316625</td>
      <td>0.3</td>
      <td>0.9</td>
      <td>0.1</td>
      <td>0.81</td>
      <td>0.54</td>
      <td>0.782340</td>
      <td>0.360000</td>
      <td>0.732844</td>
      <td>0.362131</td>
      <td>2.984962</td>
      <td>0.27</td>
      <td>0.81</td>
      <td>0.09</td>
      <td>0.36</td>
      <td>0.521560</td>
      <td>0.240000</td>
      <td>0.488563</td>
      <td>0.241421</td>
      <td>1.989975</td>
      <td>0.18</td>
      <td>0.54</td>
      <td>0.06</td>
      <td>0.755625</td>
      <td>0.347707</td>
      <td>0.707819</td>
      <td>0.349765</td>
      <td>2.883032</td>
      <td>0.260780</td>
      <td>0.782340</td>
      <td>0.086927</td>
      <td>0.160</td>
      <td>0.325708</td>
      <td>0.160947</td>
      <td>1.326650</td>
      <td>0.120000</td>
      <td>0.360000</td>
      <td>0.040000</td>
      <td>0.663037</td>
      <td>0.327637</td>
      <td>2.700631</td>
      <td>0.244281</td>
      <td>0.732844</td>
      <td>0.081427</td>
      <td>0.1619</td>
      <td>1.334504</td>
      <td>0.120710</td>
      <td>0.362131</td>
      <td>0.040237</td>
      <td>11.0</td>
      <td>0.994987</td>
      <td>2.984962</td>
      <td>0.331662</td>
      <td>0.09</td>
      <td>0.27</td>
      <td>0.03</td>
      <td>0.81</td>
      <td>0.09</td>
      <td>0.01</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.6</td>
      <td>1.5</td>
      <td>1.705872</td>
      <td>0.400000</td>
      <td>0.838387</td>
      <td>0.378418</td>
      <td>3.605551</td>
      <td>0.8</td>
      <td>0.4</td>
      <td>0.1</td>
      <td>0.36</td>
      <td>0.90</td>
      <td>1.023523</td>
      <td>0.240000</td>
      <td>0.503032</td>
      <td>0.227051</td>
      <td>2.163331</td>
      <td>0.48</td>
      <td>0.24</td>
      <td>0.06</td>
      <td>2.25</td>
      <td>2.558808</td>
      <td>0.600000</td>
      <td>1.257580</td>
      <td>0.567627</td>
      <td>5.408327</td>
      <td>1.20</td>
      <td>0.60</td>
      <td>0.15</td>
      <td>2.910000</td>
      <td>0.682349</td>
      <td>1.430181</td>
      <td>0.645532</td>
      <td>6.150610</td>
      <td>1.364698</td>
      <td>0.682349</td>
      <td>0.170587</td>
      <td>0.160</td>
      <td>0.335355</td>
      <td>0.151367</td>
      <td>1.442221</td>
      <td>0.320000</td>
      <td>0.160000</td>
      <td>0.040000</td>
      <td>0.702893</td>
      <td>0.317260</td>
      <td>3.022847</td>
      <td>0.670710</td>
      <td>0.335355</td>
      <td>0.083839</td>
      <td>0.1432</td>
      <td>1.364405</td>
      <td>0.302734</td>
      <td>0.151367</td>
      <td>0.037842</td>
      <td>13.0</td>
      <td>2.884441</td>
      <td>1.442221</td>
      <td>0.360555</td>
      <td>0.64</td>
      <td>0.32</td>
      <td>0.08</td>
      <td>0.16</td>
      <td>0.04</td>
      <td>0.01</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.8</td>
      <td>0.8</td>
      <td>1.086566</td>
      <td>0.400000</td>
      <td>0.905777</td>
      <td>0.384838</td>
      <td>3.605551</td>
      <td>0.6</td>
      <td>0.5</td>
      <td>0.9</td>
      <td>0.64</td>
      <td>0.64</td>
      <td>0.869253</td>
      <td>0.320000</td>
      <td>0.724622</td>
      <td>0.307870</td>
      <td>2.884441</td>
      <td>0.48</td>
      <td>0.40</td>
      <td>0.72</td>
      <td>0.64</td>
      <td>0.869253</td>
      <td>0.320000</td>
      <td>0.724622</td>
      <td>0.307870</td>
      <td>2.884441</td>
      <td>0.48</td>
      <td>0.40</td>
      <td>0.72</td>
      <td>1.180625</td>
      <td>0.434626</td>
      <td>0.984186</td>
      <td>0.418151</td>
      <td>3.917668</td>
      <td>0.651939</td>
      <td>0.543283</td>
      <td>0.977909</td>
      <td>0.160</td>
      <td>0.362311</td>
      <td>0.153935</td>
      <td>1.442221</td>
      <td>0.240000</td>
      <td>0.200000</td>
      <td>0.360000</td>
      <td>0.820432</td>
      <td>0.348577</td>
      <td>3.265825</td>
      <td>0.543466</td>
      <td>0.452888</td>
      <td>0.815199</td>
      <td>0.1481</td>
      <td>1.387552</td>
      <td>0.230903</td>
      <td>0.192419</td>
      <td>0.346354</td>
      <td>13.0</td>
      <td>2.163331</td>
      <td>1.802776</td>
      <td>3.244996</td>
      <td>0.36</td>
      <td>0.30</td>
      <td>0.54</td>
      <td>0.25</td>
      <td>0.45</td>
      <td>0.81</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>216935</th>
      <td>0.6</td>
      <td>0.4</td>
      <td>1.537652</td>
      <td>0.424264</td>
      <td>1.269111</td>
      <td>0.384708</td>
      <td>3.162278</td>
      <td>0.5</td>
      <td>0.1</td>
      <td>0.5</td>
      <td>0.36</td>
      <td>0.24</td>
      <td>0.922591</td>
      <td>0.254558</td>
      <td>0.761467</td>
      <td>0.230825</td>
      <td>1.897367</td>
      <td>0.30</td>
      <td>0.06</td>
      <td>0.30</td>
      <td>0.16</td>
      <td>0.615061</td>
      <td>0.169706</td>
      <td>0.507645</td>
      <td>0.153883</td>
      <td>1.264911</td>
      <td>0.20</td>
      <td>0.04</td>
      <td>0.20</td>
      <td>2.364375</td>
      <td>0.652371</td>
      <td>1.951452</td>
      <td>0.591547</td>
      <td>4.862484</td>
      <td>0.768826</td>
      <td>0.153765</td>
      <td>0.768826</td>
      <td>0.180</td>
      <td>0.538438</td>
      <td>0.163218</td>
      <td>1.341641</td>
      <td>0.212132</td>
      <td>0.042426</td>
      <td>0.212132</td>
      <td>1.610644</td>
      <td>0.488237</td>
      <td>4.013282</td>
      <td>0.634556</td>
      <td>0.126911</td>
      <td>0.634556</td>
      <td>0.1480</td>
      <td>1.216553</td>
      <td>0.192354</td>
      <td>0.038471</td>
      <td>0.192354</td>
      <td>10.0</td>
      <td>1.581139</td>
      <td>0.316228</td>
      <td>1.581139</td>
      <td>0.25</td>
      <td>0.05</td>
      <td>0.25</td>
      <td>0.01</td>
      <td>0.05</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>216936</th>
      <td>0.3</td>
      <td>0.4</td>
      <td>0.898861</td>
      <td>0.424264</td>
      <td>0.756979</td>
      <td>0.400000</td>
      <td>2.000000</td>
      <td>0.3</td>
      <td>0.4</td>
      <td>0.6</td>
      <td>0.09</td>
      <td>0.12</td>
      <td>0.269658</td>
      <td>0.127279</td>
      <td>0.227094</td>
      <td>0.120000</td>
      <td>0.600000</td>
      <td>0.09</td>
      <td>0.12</td>
      <td>0.18</td>
      <td>0.16</td>
      <td>0.359544</td>
      <td>0.169706</td>
      <td>0.302791</td>
      <td>0.160000</td>
      <td>0.800000</td>
      <td>0.12</td>
      <td>0.16</td>
      <td>0.24</td>
      <td>0.807951</td>
      <td>0.381354</td>
      <td>0.680419</td>
      <td>0.359544</td>
      <td>1.797722</td>
      <td>0.269658</td>
      <td>0.359544</td>
      <td>0.539317</td>
      <td>0.180</td>
      <td>0.321159</td>
      <td>0.169706</td>
      <td>0.848528</td>
      <td>0.127279</td>
      <td>0.169706</td>
      <td>0.254558</td>
      <td>0.573017</td>
      <td>0.302791</td>
      <td>1.513957</td>
      <td>0.227094</td>
      <td>0.302791</td>
      <td>0.454187</td>
      <td>0.1600</td>
      <td>0.800000</td>
      <td>0.120000</td>
      <td>0.160000</td>
      <td>0.240000</td>
      <td>4.0</td>
      <td>0.600000</td>
      <td>0.800000</td>
      <td>1.200000</td>
      <td>0.09</td>
      <td>0.12</td>
      <td>0.18</td>
      <td>0.16</td>
      <td>0.24</td>
      <td>0.36</td>
    </tr>
    <tr>
      <th>216937</th>
      <td>0.9</td>
      <td>0.3</td>
      <td>0.711952</td>
      <td>0.400000</td>
      <td>0.970654</td>
      <td>0.372424</td>
      <td>3.464102</td>
      <td>0.5</td>
      <td>0.4</td>
      <td>0.6</td>
      <td>0.81</td>
      <td>0.27</td>
      <td>0.640756</td>
      <td>0.360000</td>
      <td>0.873589</td>
      <td>0.335182</td>
      <td>3.117691</td>
      <td>0.45</td>
      <td>0.36</td>
      <td>0.54</td>
      <td>0.09</td>
      <td>0.213585</td>
      <td>0.120000</td>
      <td>0.291196</td>
      <td>0.111727</td>
      <td>1.039230</td>
      <td>0.15</td>
      <td>0.12</td>
      <td>0.18</td>
      <td>0.506875</td>
      <td>0.284781</td>
      <td>0.691059</td>
      <td>0.265148</td>
      <td>2.466272</td>
      <td>0.355976</td>
      <td>0.284781</td>
      <td>0.427171</td>
      <td>0.160</td>
      <td>0.388262</td>
      <td>0.148970</td>
      <td>1.385641</td>
      <td>0.200000</td>
      <td>0.160000</td>
      <td>0.240000</td>
      <td>0.942169</td>
      <td>0.361495</td>
      <td>3.362445</td>
      <td>0.485327</td>
      <td>0.388262</td>
      <td>0.582392</td>
      <td>0.1387</td>
      <td>1.290116</td>
      <td>0.186212</td>
      <td>0.148970</td>
      <td>0.223455</td>
      <td>12.0</td>
      <td>1.732051</td>
      <td>1.385641</td>
      <td>2.078461</td>
      <td>0.25</td>
      <td>0.20</td>
      <td>0.30</td>
      <td>0.16</td>
      <td>0.24</td>
      <td>0.36</td>
    </tr>
    <tr>
      <th>216938</th>
      <td>0.6</td>
      <td>0.1</td>
      <td>0.577170</td>
      <td>0.316228</td>
      <td>0.876295</td>
      <td>0.320780</td>
      <td>3.741657</td>
      <td>0.5</td>
      <td>0.2</td>
      <td>0.6</td>
      <td>0.36</td>
      <td>0.06</td>
      <td>0.346302</td>
      <td>0.189737</td>
      <td>0.525777</td>
      <td>0.192468</td>
      <td>2.244994</td>
      <td>0.30</td>
      <td>0.12</td>
      <td>0.36</td>
      <td>0.01</td>
      <td>0.057717</td>
      <td>0.031623</td>
      <td>0.087629</td>
      <td>0.032078</td>
      <td>0.374166</td>
      <td>0.05</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.333125</td>
      <td>0.182517</td>
      <td>0.505771</td>
      <td>0.185145</td>
      <td>2.159572</td>
      <td>0.288585</td>
      <td>0.115434</td>
      <td>0.346302</td>
      <td>0.100</td>
      <td>0.277109</td>
      <td>0.101440</td>
      <td>1.183216</td>
      <td>0.158114</td>
      <td>0.063246</td>
      <td>0.189737</td>
      <td>0.767893</td>
      <td>0.281098</td>
      <td>3.278795</td>
      <td>0.438147</td>
      <td>0.175259</td>
      <td>0.525777</td>
      <td>0.1029</td>
      <td>1.200250</td>
      <td>0.160390</td>
      <td>0.064156</td>
      <td>0.192468</td>
      <td>14.0</td>
      <td>1.870829</td>
      <td>0.748331</td>
      <td>2.244994</td>
      <td>0.25</td>
      <td>0.10</td>
      <td>0.30</td>
      <td>0.04</td>
      <td>0.12</td>
      <td>0.36</td>
    </tr>
    <tr>
      <th>216939</th>
      <td>0.6</td>
      <td>0.4</td>
      <td>1.095160</td>
      <td>0.374166</td>
      <td>0.752558</td>
      <td>0.328634</td>
      <td>3.464102</td>
      <td>0.2</td>
      <td>0.6</td>
      <td>0.3</td>
      <td>0.36</td>
      <td>0.24</td>
      <td>0.657096</td>
      <td>0.224499</td>
      <td>0.451535</td>
      <td>0.197180</td>
      <td>2.078461</td>
      <td>0.12</td>
      <td>0.36</td>
      <td>0.18</td>
      <td>0.16</td>
      <td>0.438064</td>
      <td>0.149666</td>
      <td>0.301023</td>
      <td>0.131453</td>
      <td>1.385641</td>
      <td>0.08</td>
      <td>0.24</td>
      <td>0.12</td>
      <td>1.199375</td>
      <td>0.409771</td>
      <td>0.824171</td>
      <td>0.359906</td>
      <td>3.793745</td>
      <td>0.219032</td>
      <td>0.657096</td>
      <td>0.328548</td>
      <td>0.140</td>
      <td>0.281581</td>
      <td>0.122963</td>
      <td>1.296148</td>
      <td>0.074833</td>
      <td>0.224499</td>
      <td>0.112250</td>
      <td>0.566343</td>
      <td>0.247316</td>
      <td>2.606936</td>
      <td>0.150512</td>
      <td>0.451535</td>
      <td>0.225767</td>
      <td>0.1080</td>
      <td>1.138420</td>
      <td>0.065727</td>
      <td>0.197180</td>
      <td>0.098590</td>
      <td>12.0</td>
      <td>0.692820</td>
      <td>2.078461</td>
      <td>1.039230</td>
      <td>0.04</td>
      <td>0.12</td>
      <td>0.06</td>
      <td>0.36</td>
      <td>0.18</td>
      <td>0.09</td>
    </tr>
  </tbody>
</table>
<p>216940 rows × 65 columns</p>
</div>




```python
intersactions = pd.DataFrame(data=poly.fit_transform(train[v]), columns=poly.get_feature_names(v))
intersactions.drop(v, axis=1, inplace=True)
train = pd.concat([train, intersactions], axis = 1) #옆으로 붙여야한다!
#sample을 붙이면 axis = 0
```


```python
selector = VarianceThreshold(threshold=.01)
selector.fit(train.drop(['id', 'target'], axis=1))

f = np.vectorize(lambda x : not x)

v = train.drop(['id', 'target'], axis=1).columns[f(selector.get_support())]
print('{} variables have too low variance.'.format(len(v)))
print('These variavels are {}'.format(list(v)))
```

    28 variables have too low variance.
    These variavels are ['ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_12', 'ps_car_14', 'ps_car_11_cat_te', 'ps_ind_05_cat_2', 'ps_ind_05_cat_5', 'ps_car_01_cat_1', 'ps_car_01_cat_2', 'ps_car_04_cat_3', 'ps_car_04_cat_4', 'ps_car_04_cat_5', 'ps_car_04_cat_6', 'ps_car_04_cat_7', 'ps_car_06_cat_2', 'ps_car_06_cat_5', 'ps_car_06_cat_8', 'ps_car_06_cat_12', 'ps_car_06_cat_16', 'ps_car_06_cat_17', 'ps_car_09_cat_4', 'ps_car_10_cat_1', 'ps_car_10_cat_2', 'ps_car_12^2', 'ps_car_12 ps_car_14', 'ps_car_14^2']


#### 이유한 님 팁
* 1000개의 피쳐가 있을 때 피쳐를 20개씩 뺐다 넣다 하면서 성능을 보자!!
* 20개 모델 baseline + random choosing 20
* 40 모델 학습
* if 성능 향상 -> feature importance 상위 10%에 새로 추가된거 생기면 향산된걸 남기고 
* 안생기면 계속 random choosing
* 반복


```python
X_train = train.drop(['id','target'],axis=1)
y_train = train['target']

feat_labels = X_train.columns

rf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)

rf.fit(X_train, y_train)
importances = rf.feature_importances_

indices = np.argsort(rf.feature_importances_)[::-1]

for f in range(X_train.shape[1]):
    print("%2d) %-*s %f" % (f +1, 30, feat_labels[indices[f]], importances[indices[f]]))


```

     1) ps_car_11_cat_te               0.021144
     2) ps_car_12 ps_car_13            0.017390
     3) ps_car_13                      0.017361
     4) ps_car_13^2                    0.017307
     5) ps_reg_03 ps_car_13            0.017075
     6) ps_car_13 ps_car_14            0.017067
     7) ps_car_13 ps_car_15            0.016823
     8) ps_reg_01 ps_car_13            0.016773
     9) ps_reg_03 ps_car_14            0.016233
    10) ps_reg_03 ps_car_12            0.015462
    11) ps_reg_03 ps_car_15            0.015181
    12) ps_car_14 ps_car_15            0.015056
    13) ps_car_13 ps_calc_02           0.014764
    14) ps_car_13 ps_calc_01           0.014746
    15) ps_reg_02 ps_car_13            0.014710
    16) ps_car_13 ps_calc_03           0.014702
    17) ps_reg_01 ps_reg_03            0.014665
    18) ps_reg_01 ps_car_14            0.014378
    19) ps_reg_03^2                    0.014235
    20) ps_reg_03                      0.014196
    21) ps_reg_03 ps_calc_03           0.013807
    22) ps_reg_03 ps_calc_02           0.013738
    23) ps_reg_03 ps_calc_01           0.013705
    24) ps_car_14 ps_calc_02           0.013652
    25) ps_calc_10                     0.013646
    26) ps_car_14 ps_calc_03           0.013537
    27) ps_car_14 ps_calc_01           0.013527
    28) ps_calc_14                     0.013388
    29) ps_car_12 ps_car_14            0.012970
    30) ps_ind_03                      0.012921
    31) ps_car_14                      0.012741
    32) ps_car_14^2                    0.012730
    33) ps_reg_02 ps_car_14            0.012697
    34) ps_calc_11                     0.012619
    35) ps_reg_02 ps_reg_03            0.012489
    36) ps_ind_15                      0.012116
    37) ps_car_12 ps_car_15            0.010944
    38) ps_car_15 ps_calc_01           0.010857
    39) ps_car_15 ps_calc_03           0.010839
    40) ps_car_15 ps_calc_02           0.010837
    41) ps_car_12 ps_calc_01           0.010477
    42) ps_calc_13                     0.010477
    43) ps_car_12 ps_calc_03           0.010310
    44) ps_car_12 ps_calc_02           0.010296
    45) ps_reg_02 ps_car_15            0.010205
    46) ps_reg_01 ps_car_15            0.010177
    47) ps_calc_02 ps_calc_03          0.010077
    48) ps_calc_01 ps_calc_02          0.010013
    49) ps_calc_01 ps_calc_03          0.010005
    50) ps_calc_08                     0.009867
    51) ps_calc_07                     0.009857
    52) ps_reg_01 ps_car_12            0.009473
    53) ps_reg_02 ps_car_12            0.009319
    54) ps_reg_02 ps_calc_01           0.009294
    55) ps_reg_02 ps_calc_03           0.009237
    56) ps_reg_02 ps_calc_02           0.009146
    57) ps_calc_06                     0.009092
    58) ps_reg_01 ps_calc_02           0.009054
    59) ps_reg_01 ps_calc_03           0.009041
    60) ps_reg_01 ps_calc_01           0.009020
    61) ps_calc_09                     0.008794
    62) ps_ind_01                      0.008606
    63) ps_calc_05                     0.008298
    64) ps_calc_04                     0.008168
    65) ps_calc_12                     0.008015
    66) ps_reg_01 ps_reg_02            0.008015
    67) ps_car_15                      0.006130
    68) ps_car_15^2                    0.006130
    69) ps_calc_03                     0.006001
    70) ps_calc_01^2                   0.005975
    71) ps_calc_01                     0.005964
    72) ps_calc_03^2                   0.005964
    73) ps_calc_02                     0.005950
    74) ps_calc_02^2                   0.005943
    75) ps_car_12                      0.005358
    76) ps_car_12^2                    0.005348
    77) ps_reg_02^2                    0.004993
    78) ps_reg_02                      0.004986
    79) ps_reg_01^2                    0.004140
    80) ps_reg_01                      0.004118
    81) ps_car_11                      0.003796
    82) ps_ind_05_cat_0                0.003564
    83) ps_ind_17_bin                  0.002840
    84) ps_calc_17_bin                 0.002701
    85) ps_calc_16_bin                 0.002597
    86) ps_calc_19_bin                 0.002554
    87) ps_calc_18_bin                 0.002529
    88) ps_ind_04_cat_1                0.002405
    89) ps_car_01_cat_11               0.002399
    90) ps_ind_16_bin                  0.002393
    91) ps_ind_04_cat_0                0.002378
    92) ps_ind_07_bin                  0.002333
    93) ps_car_09_cat_2                0.002313
    94) ps_ind_02_cat_1                0.002269
    95) ps_car_09_cat_0                0.002100
    96) ps_car_01_cat_7                0.002089
    97) ps_ind_02_cat_2                0.002078
    98) ps_calc_20_bin                 0.002072
    99) ps_ind_06_bin                  0.002041
    100) ps_car_06_cat_1                0.002002
    101) ps_calc_15_bin                 0.001996
    102) ps_car_07_cat_1                0.001966
    103) ps_ind_08_bin                  0.001946
    104) ps_car_09_cat_1                0.001828
    105) ps_car_06_cat_11               0.001787
    106) ps_ind_18_bin                  0.001739
    107) ps_ind_09_bin                  0.001719
    108) ps_car_01_cat_10               0.001598
    109) ps_car_01_cat_9                0.001577
    110) ps_car_01_cat_6                0.001549
    111) ps_car_06_cat_14               0.001547
    112) ps_car_01_cat_4                0.001530
    113) ps_ind_05_cat_6                0.001501
    114) ps_ind_02_cat_3                0.001432
    115) ps_car_07_cat_0                0.001369
    116) ps_car_02_cat_1                0.001337
    117) ps_car_01_cat_8                0.001330
    118) ps_car_08_cat_1                0.001327
    119) ps_car_02_cat_0                0.001313
    120) ps_car_06_cat_4                0.001225
    121) ps_ind_05_cat_4                0.001216
    122) ps_ind_02_cat_4                0.001156
    123) ps_car_01_cat_5                0.001143
    124) ps_car_06_cat_6                0.001095
    125) ps_car_06_cat_10               0.001055
    126) ps_car_04_cat_1                0.001036
    127) ps_ind_05_cat_2                0.001030
    128) ps_car_06_cat_7                0.001003
    129) ps_car_04_cat_2                0.000980
    130) ps_car_01_cat_3                0.000885
    131) ps_car_09_cat_3                0.000883
    132) ps_ind_14                      0.000862
    133) ps_car_01_cat_0                0.000854
    134) ps_car_06_cat_15               0.000831
    135) ps_car_06_cat_9                0.000785
    136) ps_ind_05_cat_1                0.000755
    137) ps_car_10_cat_1                0.000704
    138) ps_car_06_cat_3                0.000698
    139) ps_ind_05_cat_3                0.000685
    140) ps_ind_12_bin                  0.000671
    141) ps_car_09_cat_4                0.000631
    142) ps_car_01_cat_2                0.000569
    143) ps_car_04_cat_8                0.000557
    144) ps_car_06_cat_17               0.000513
    145) ps_car_06_cat_16               0.000454
    146) ps_car_04_cat_9                0.000443
    147) ps_car_06_cat_12               0.000420
    148) ps_car_06_cat_13               0.000396
    149) ps_car_01_cat_1                0.000381
    150) ps_ind_05_cat_5                0.000307
    151) ps_car_06_cat_5                0.000284
    152) ps_ind_11_bin                  0.000217
    153) ps_car_04_cat_6                0.000193
    154) ps_ind_13_bin                  0.000150
    155) ps_car_04_cat_3                0.000141
    156) ps_car_06_cat_2                0.000137
    157) ps_car_04_cat_5                0.000100
    158) ps_car_06_cat_8                0.000093
    159) ps_car_04_cat_7                0.000083
    160) ps_ind_10_bin                  0.000074
    161) ps_car_10_cat_2                0.000058
    162) ps_car_04_cat_4                0.000042



```python
sfm = SelectFromModel(rf, threshold='median', prefit=True)
print('Number of features before selection: {}'.format(X_train.shape[1]))
n_features = sfm.transform(X_train).shape[1]
print('Number of features after selection: {}'.format(n_features))
selected_vars = list(feat_labels[sfm.get_support()])
```

    Number of features before selection: 162
    Number of features after selection: 81



```python
train = train[selected_vars + ['target']]
```


```python
scaler = StandardScaler()
scaler.fit_transform(train.drop(['target'], axis=1))
```




    array([[-0.45941104, -1.26665356,  1.05087653, ..., -0.72553616,
            -1.01071913, -1.06173767],
           [ 1.55538958,  0.95034274, -0.63847299, ..., -1.06120876,
            -1.01071913,  0.27907892],
           [ 1.05168943, -0.52765479, -0.92003125, ...,  1.95984463,
            -0.56215309, -1.02449277],
           ...,
           [-0.9631112 ,  0.58084336,  0.48776003, ..., -0.46445747,
             0.18545696,  0.27907892],
           [-0.9631112 , -0.89715418, -1.48314775, ..., -0.91202093,
            -0.41263108,  0.27907892],
           [-0.45941104, -1.26665356,  1.61399304, ...,  0.28148164,
            -0.11358706, -0.72653353]])



* [이유한님 유튜브](https://www.youtube.com/watch?v=Fsbx-q3IOek&list=PLC_wC_PMBL5NLKkMooi-n4iK4gv3VqXyo&index=4)
* [케글 고수님](https://www.kaggle.com/bertcarremans/data-preparation-exploration/comments)


```python

```
